
import numpy as np
import math
import matplotlib.pyplot as plt
import csv

def get_binomial_log_likelihood(obs, probs):
    N = sum(obs)
    k = obs[0]
    binomial_coeff = math.factorial(N) / (math.factorial(N - k) * math.factorial(k))
    prod_probs = obs[0] * math.log(probs[0]) + obs[1] * math.log(1 - probs[0])
    log_lik = binomial_coeff + prod_probs
    return log_lik

data = []
with open("cluster.csv") as tsv:
    for line in csv.reader(tsv):
        data = [5,9,8,4,7]

head_counts = np.array(data)
tail_counts = 10 - head_counts
experiments = list(zip(head_counts, tail_counts))

pA_heads = np.zeros(100)
pA_heads[0] = 0.60
pB_heads = np.zeros(100)
pB_heads[0] = 0.50

delta = 0.001
j = 0
improvement = float('inf')

while (improvement > delta):
    expectation_A = np.zeros((len(experiments), 2), dtype=float)
    expectation_B = np.zeros((len(experiments), 2), dtype=float)
    
    for i in range(0,len(experiments)):
        e = experiments[i]
        ll_A = get_binomial_log_likelihood(e, np.array([pA_heads[j], 1 - pA_heads[j]]))
        ll_B = get_binomial_log_likelihood(e, np.array([pB_heads[j], 1 - pB_heads[j]]))
        
        weightA = math.exp(ll_A) / (math.exp(ll_A) + math.exp(ll_B))
        weightB = math.exp(ll_B) / (math.exp(ll_A) + math.exp(ll_B))
        
        expectation_A[i] = np.dot(weightA, e)
        expectation_B[i] = np.dot(weightB, e)
        
        pA_heads[j + 1] = sum(expectation_A)[0] / sum(sum(expectation_A))
        pB_heads[j + 1] = sum(expectation_B)[0] / sum(sum(expectation_B))
        
        improvement = max(abs(np.array([pA_heads[j + 1], pB_heads[j + 1]]) -
                            np.array([pA_heads[j], pB_heads[j]])))
        
        j = j + 1

plt.figure()
plt.plot(range(0, j), pA_heads[0:j])
plt.plot(range(0, j), pB_heads[0:j])
plt.show()



K-Mean Algorithm 


from sklearn.cluster import KMeans
from sklearn import metrics
import numpy as np
import matplotlib.pyplot as plt
from random import random

x1 = np.array([random() for i in range(100)])
x2 = np.array([random() for i in range(100)])
print(x1)
plt.plot()
plt.xlim([0, 10])
plt.ylim([0, 10])
plt.title('Dataset')
plt.scatter(x1, x2)
plt.show()

plt.plot()
X = np.array(list(zip(x1, x2))).reshape(len(x1), 2)
colors = ['b', 'g', 'r','c', 'm', 'y']
markers = ['o', 'v', 's','o', 'v', 's']

K = 3
kmeans_model = KMeans(n_clusters=K).fit(X)

plt.plot()
for i, l in enumerate(kmeans_model.labels_):
    plt.plot(x1[i], x2[i], color=colors[l], marker=markers[l], ls='None')
    plt.xlim([0, 1])
    plt.ylim([0, 1])

plt.show()
